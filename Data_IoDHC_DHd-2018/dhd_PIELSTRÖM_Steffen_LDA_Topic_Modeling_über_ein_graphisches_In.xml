<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/2.0"
     xml:id="dhd_PIELSTRÖM_Steffen_LDA_Topic_Modeling_über_ein_graphisches_In">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title xml:lang="de">LDA Topic Modeling über ein graphisches Interface</title>
            <author>
               <persName>
                  <surname>Simmler</surname>
                  <forename>Severin</forename>
               </persName>
               <affiliation>
                  <orgName>
                     <name type="main">Universität Würzburg</name>
                  </orgName>
                  <country>Deutschland</country>
               </affiliation>
            </author>
            <author>
               <persName>
                  <surname>Vitt</surname>
                  <forename>Thorsten</forename>
               </persName>
               <affiliation>
                  <orgName>
                     <name type="main">Universität Würzburg</name>
                  </orgName>
                  <country>Deutschland</country>
               </affiliation>
            </author>
            <author>
               <persName>
                  <surname>Pielström</surname>
                  <forename>Steffen</forename>
               </persName>
               <affiliation>
                  <orgName>
                     <name type="main">Universität Würzburg</name>
                  </orgName>
                  <country>Deutschland</country>
               </affiliation>
            </author>
         </titleStmt>
      </fileDesc>
      <profileDesc>
         <textClass>
            <keywords n="category">
               <term>Poster</term>
            </keywords>
            <keywords n="keywords">
               <term>Topic Modeling</term>
               <term>Python</term>
            </keywords>
            <keywords n="topics">
               <term>Inhaltsanalyse</term>
               <term>Modellierung</term>
               <term>Visualisierung</term>
            </keywords>
         </textClass>
      </profileDesc>
   </teiHeader>
   <text xml:lang="de">
      <body>
         <p>
            <anchor id="id_docs-internal-guid-2033756f-ba92-c518-3bed-9e08eaf11c1e"/>LDA (Latent Dirichlet Allocation) Topic Modeling ist ein computergestütztes Verfahren zur semantischen Analyse digitaler Textsammlungen. Hierbei werden mit Hilfe eines probabilistischen Verfahrens aus Texten eine Reihe sogenannter “Topics” generiert: Gruppen semantisch ähnlicher Begriffe, die über mehrere Texte gemeinsam auftreten und im Modell als Wahrscheinlichkeitsverteilungen über die Gesamtheit des analysierten Vokabulars repräsentiert werden. Das heißt, daß zum Beispiel in einem Topic zum Thema Seefahrt nautische Begriffe besonders hohe Wahrscheinlichkeiten haben (Blei 2012, Steyvers und Griffiths 2006).
            </p>
         <p>In den letzten Jahren ist das Interesse an LDA als Verfahren für die Analyse literarischer Textcorpora auf Seiten der digitalen Geisteswissenschaften stark gestiegen. Im Kontrast zu diesem gesteigerten Interesse ist die Anwendung der Methode allerdings nicht wesentlich leichter geworden. Gängige Implementierungen des LDA-Algorithmus werden entweder über ein kommandozeilenbasiertes Java-Programm (MALLET von McCallum 2002) oder über Skripte in der Programmiersprache Python (Gensim von Rehurek und Sojka 2010) angesprochen. Die Aufbereitung der Daten vor dem Topic Modeling, das sog. “Preprocessing” und die Analyse der Ergebnisse hinterher geschieht dann zumindest in Teilen häufig unter Verwendung weiterer Programme bzw. Arbeitsumgebungen. Alles in allem erfordert die Durchführung einer LDA-basierten Inhaltsanalyse damit zur Zeit relativ umfangreiche technische Kenntnisse.</p>
         <p>Um den Zugang zu dieser Methode zu erleichtern entwickeln wir im Rahmen von DARIAH-DE (https://de.dariah.eu/) zur Zeit eine ausführlich dokumentierte Python-Programmbibliothek, die es ermöglichen soll, den gesamten Arbeitsprozess einer LDA-basierten Analyse in einer einzigen Umgebung durchzuführen (<ptr target="https://github.com/DARIAH-DE/Topics"/>). Neben der Schaffung integrierter, flexibler Arbeitsabläufe, die vollständig in einer Programmiersprache und Umgebung stattfinden können,  wollen wir auch Forscherinnen und Forschern ohne vorherige Programmierkenntnisse eine Möglichkeit zu bieten, Topic Modeling als Verfahren kennen zu lernen und an eigenen Daten auszuprobieren.
            </p>
         <p>Um einen leichtgewichtigen Einstieg in diese Thematik zu bieten haben wir auf Basis unserer Programmbibliothek, der Python-nativen LDA-Implementierung von Allan Riddell (https://pypi.python.org/pypi/lda) und dem Python-Microframework “Flask” (<ptr target="http://flask.pocoo.org/"/>) einen sogenannten GUI-Demonstrator entwickelt (Abb. 1). Dabei handelt es sich um eine browserbasierte graphische Benutzeroberfläche für die DARIAH-Topics Bibliothek, mit der sich ein basaler Topic-Modeling Analysevorgang lokal, mit eigenen Daten, aber eben ohne jegliche Programmierkenntnisse durchführen lässt.
            </p>
         <p>Der GUI-Demonstrator übernimmt und erklärt hierbei exemplarisch alle Arbeitsschritte einer einfachen Analyse. Zunächst werden Textdateien über ein Auswahlmenü eingelesen und tokenisiert. Nutzerinnen und Nutzer können zur Reduktion des Vokabulars auf die Funktionswörter vorgeben, wie viele der häufigsten Wörter aus den Texten entfernt werden sollen, oder alternativ über ein weiteres Auswahlmenü eine externe Stopwortliste einbinden. Die Anzahl der zu berechnenden Topics und die Zahl der Iterationen, über die die Berechnung durchgeführt werden soll, ein Faktor, der die Qualität der Ergebnisse entscheidend beeinflusst, können ebenfalls über das Interface gesteuert werden. In der derzeitigen Form generiert das Programm als Output eine Tabelle mit den zehn am stärksten gewichteten Wörtern in jedem Topic, sowie ein Heatmap als Übersicht über die Verteilung der Topics über die Texte.</p>
         <p>Im Fokus der gegenwärtigen Weiterentwicklung steht die Gestaltung interaktiver Outputs mit Hilfe von Bokeh (<ptr target="https://bokeh.pydata.org/"/>), die einen flexibleren Zugriff auf eine größere Zahl von Aspekten der Modellierungsergebnisse ermöglichen sollen.
            </p>
         <p>Das Ziel dieser Entwicklung bleibt aber in erster Linie ein didaktisches: Der GUI-Demonstrator führt die  grundsätzlichen Möglichkeiten der Methode vor und informiert gleichzeitig über die Abläufe im Hintergrund, so dass der Schritt hin zur Verwendung der gleichen Funktionalitäten in einem vorbereiteten Notebook mit interaktiven Codeblöcken, das schnell an die spezifischen Bedürfnisse eine bestimmten Forschungsfrage angepasst werden kann, nur noch klein ist.</p>
         <p>
            <figure>
               <graphic url="PIELSTR_M_Steffen_LDA_Topic_Modeling__ber_ein_graphisches_In-10000201000004B50000038C09038E5B.png"/>
               <head>Abbildung 1.: Screenshot</head>
            </figure>
         </p>
      </body>
      <back>
         <div type="bibliogr">
            <listBibl>
               <head>Bibliographie</head>
               <bibl>
                  <anchor id="id_docs-internal-guid-2033756f-ba93-21db-bc18-ce75d429b064"/>
                  <hi rend="bold">Blei, David M.</hi>
                        (2012): „Probabilistic Topic Models“, in 
                        <hi rend="italic">Communication of the ACM</hi>
                        55, Nr. 4 (2012): 77–84. doi:10.1145/2133806.2133826.
                    </bibl>
               <bibl>
                  <hi rend="bold">McCallum, Andrew K.</hi>
                        (2002): <hi rend="italic">MALLET : A Machine Learning for Language Toolkit</hi>.
                        <ref target="http://mallet.cs.umass.edu/">
                     <hi rend="underline">http://mallet.cs.umass.edu</hi>
                  </ref>.
                    </bibl>
               <bibl>
                  <hi rend="bold">Rehurek, Radim/ Sojka, Petr</hi>
                        (2010): "Software framework for topic modelling with large corpora."
                        <hi rend="italic">In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</hi>.
                    </bibl>
               <bibl>
                  <hi rend="bold">Steyvers, Mark/ Griffiths, Tom</hi>
                        (2006): „Probabilistic Topic Models“, in
                        <hi rend="italic">Latent Semantic Analysis: A Road to Meaning</hi>, herausgegeben von T. Landauer, D. McNamara, S. Dennis, und W. Kintsch. Laurence Erlbaum.
                    </bibl>
            </listBibl>
         </div>
      </back>
   </text>
</TEI>
